# neostock éƒ¨ç½²è¿ç»´æ‰‹å†Œ

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾› neostock ä¸­å›½è‚¡ç¥¨åˆ†æå¹³å°çš„å®Œæ•´éƒ¨ç½²å’Œè¿ç»´æŒ‡å—ï¼ŒåŸºäº PO ä¸»æ¸…å•éªŒè¯è¦æ±‚ï¼Œç¡®ä¿ç”Ÿäº§ç¯å¢ƒçš„é«˜å¯ç”¨æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

## ç¯å¢ƒé…ç½®

### ç”Ÿäº§ç¯å¢ƒè¦æ±‚

#### è®¡ç®—èµ„æº
- **WebæœåŠ¡å™¨**: 2x t3.medium (4 vCPU, 8GB RAM)
- **æ•°æ®åº“æœåŠ¡å™¨**: 1x t3.small (2 vCPU, 4GB RAM) 
- **è´Ÿè½½å‡è¡¡**: Application Load Balancer
- **å­˜å‚¨**: EBS gp3, 100GB (æ•°æ®) + 20GB (æ—¥å¿—)

#### ç½‘ç»œé…ç½®
- **VPC**: ä¸“ç”¨è™šæ‹Ÿç§æœ‰äº‘
- **å­ç½‘**: å…¬æœ‰å­ç½‘(ALB) + ç§æœ‰å­ç½‘(åº”ç”¨æœåŠ¡å™¨)
- **å®‰å…¨ç»„**: ä¸¥æ ¼çš„å…¥ç«™è§„åˆ™é…ç½®
- **CDN**: CloudFrontåˆ†å‘é™æ€èµ„æº

#### ç›‘æ§å’Œå¤‡ä»½
- **ç›‘æ§**: CloudWatch + DataDog APM
- **æ—¥å¿—**: CloudWatch Logs + ELK Stack
- **å¤‡ä»½**: è‡ªåŠ¨åŒ–æ•°æ®åº“å¤‡ä»½(å¢é‡+å…¨é‡)
- **å‘Šè­¦**: å¤šçº§å‘Šè­¦ç­–ç•¥é…ç½®

### åŸºç¡€è®¾æ–½å³ä»£ç  (IaC)

#### Terraformä¸»é…ç½®
```hcl
# terraform/main.tf
terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
  
  backend "s3" {
    bucket = "neostock-terraform-state"
    key    = "production/terraform.tfstate"
    region = "us-west-2"
  }
}

provider "aws" {
  region = var.aws_region
  
  default_tags {
    tags = {
      Project     = "neostock"
      Environment = var.environment
      ManagedBy   = "terraform"
    }
  }
}

# VPCé…ç½®
module "vpc" {
  source = "./modules/vpc"
  
  vpc_cidr             = var.vpc_cidr
  availability_zones   = var.availability_zones
  public_subnet_cidrs  = var.public_subnet_cidrs
  private_subnet_cidrs = var.private_subnet_cidrs
  
  tags = local.common_tags
}

# åº”ç”¨æœåŠ¡å™¨
module "app_servers" {
  source = "./modules/ec2"
  
  instance_type        = var.app_instance_type
  min_size            = var.app_min_size
  max_size            = var.app_max_size
  desired_capacity    = var.app_desired_capacity
  
  vpc_id              = module.vpc.vpc_id
  private_subnet_ids  = module.vpc.private_subnet_ids
  security_group_ids  = [module.security_groups.app_sg_id]
  
  user_data = base64encode(templatefile("${path.module}/user-data/app-server.sh", {
    environment = var.environment
  }))
  
  tags = local.common_tags
}

# æ•°æ®åº“
module "database" {
  source = "./modules/rds"
  
  engine                = "sqlite" # æˆ– "postgres" for future
  instance_class        = var.db_instance_class
  allocated_storage     = var.db_allocated_storage
  
  vpc_id                = module.vpc.vpc_id
  private_subnet_ids    = module.vpc.private_subnet_ids
  security_group_ids    = [module.security_groups.db_sg_id]
  
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "sun:04:00-sun:05:00"
  
  tags = local.common_tags
}

# è´Ÿè½½å‡è¡¡
module "load_balancer" {
  source = "./modules/alb"
  
  vpc_id            = module.vpc.vpc_id
  public_subnet_ids = module.vpc.public_subnet_ids
  security_group_ids = [module.security_groups.alb_sg_id]
  
  target_group_arn = module.app_servers.target_group_arn
  
  ssl_certificate_arn = var.ssl_certificate_arn
  
  tags = local.common_tags
}
```

#### åº”ç”¨æœåŠ¡å™¨é…ç½®
```hcl
# terraform/modules/ec2/main.tf
resource "aws_launch_template" "app" {
  name_prefix   = "${var.app_name}-"
  image_id      = data.aws_ami.app.id
  instance_type = var.instance_type
  
  vpc_security_group_ids = var.security_group_ids
  
  user_data = var.user_data
  
  tag_specifications {
    resource_type = "instance"
    tags = merge(var.tags, {
      Name = "${var.app_name}-app"
      Type = "application"
    })
  }
  
  lifecycle {
    create_before_destroy = true
  }
}

resource "aws_autoscaling_group" "app" {
  name                = "${var.app_name}-asg"
  vpc_zone_identifier = var.private_subnet_ids
  target_group_arns   = [aws_lb_target_group.app.arn]
  health_check_type   = "ELB"
  health_check_grace_period = 300
  
  min_size         = var.min_size
  max_size         = var.max_size
  desired_capacity = var.desired_capacity
  
  launch_template {
    id      = aws_launch_template.app.id
    version = "$Latest"
  }
  
  tag {
    key                 = "Name"
    value               = "${var.app_name}-asg"
    propagate_at_launch = false
  }
}
```

### ç¯å¢ƒå˜é‡é…ç½®

#### ç”Ÿäº§ç¯å¢ƒå˜é‡
```bash
# .env.production
NODE_ENV=production
PORT=3000

# æ•°æ®åº“é…ç½®
DATABASE_URL=sqlite:///var/lib/neostock/production.db
DATABASE_POOL_SIZE=10
DATABASE_TIMEOUT=30000

# è®¤è¯é…ç½®
BETTER_AUTH_SECRET=super-secure-secret-key-production
BETTER_AUTH_URL=https://api.neostock.com
CORS_ORIGIN=https://neostock.com

# æ•°æ®æºé…ç½®
TUSHARE_API_TOKEN=your-production-tushare-token
TUSHARE_API_URL=https://api.tushare.pro
BACKUP_DATA_SOURCES=sina,netease,yahoo
DATA_FETCH_SCHEDULE=0 17 * * *
DATA_FETCH_TIMEOUT=300000

# ç¼“å­˜é…ç½®
REDIS_URL=redis://elasticache-cluster:6379
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# ç›‘æ§é…ç½®
DATADOG_API_KEY=your-datadog-api-key
NEW_RELIC_LICENSE_KEY=your-newrelic-license-key
SENTRY_DSN=your-sentry-dsn
LOG_LEVEL=info

# å®‰å…¨é…ç½®
RATE_LIMIT_MAX=1000
RATE_LIMIT_WINDOW=900000
SESSION_SECRET=production-session-secret
ENCRYPTION_KEY=production-encryption-key

# æ–‡ä»¶å­˜å‚¨
S3_BUCKET=neostock-production-assets
S3_REGION=us-west-2
CDN_BASE_URL=https://cdn.neostock.com

# é€šçŸ¥é…ç½®
SMTP_HOST=smtp.amazonses.com
SMTP_PORT=587
SMTP_USER=your-ses-user
SMTP_PASS=your-ses-password
SLACK_WEBHOOK_URL=your-slack-webhook-url
```

## éƒ¨ç½²æµç¨‹

### è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬

#### ä¸»éƒ¨ç½²è„šæœ¬
```bash
#!/bin/bash
# scripts/deploy.sh

set -euo pipefail

ENVIRONMENT=${1:-staging}
VERSION=${2:-latest}
BLUE_GREEN=${3:-false}

echo "ğŸš€ å¼€å§‹éƒ¨ç½² neostock åˆ° $ENVIRONMENT ç¯å¢ƒ"
echo "ç‰ˆæœ¬: $VERSION"
echo "è“ç»¿éƒ¨ç½²: $BLUE_GREEN"

# æ£€æŸ¥å…ˆå†³æ¡ä»¶
check_prerequisites() {
    echo "ğŸ“‹ æ£€æŸ¥éƒ¨ç½²å…ˆå†³æ¡ä»¶..."
    
    # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
    required_vars=(
        "AWS_ACCOUNT_ID"
        "AWS_REGION" 
        "ECR_REPOSITORY"
        "ECS_CLUSTER"
        "ECS_SERVICE"
    )
    
    for var in "${required_vars[@]}"; do
        if [[ -z "${!var:-}" ]]; then
            echo "âŒ ç¯å¢ƒå˜é‡ $var æœªè®¾ç½®"
            exit 1
        fi
    done
    
    # æ£€æŸ¥AWS CLI
    if ! command -v aws &> /dev/null; then
        echo "âŒ AWS CLI æœªå®‰è£…"
        exit 1
    fi
    
    # æ£€æŸ¥Docker
    if ! command -v docker &> /dev/null; then
        echo "âŒ Docker æœªå®‰è£…"
        exit 1
    fi
    
    echo "âœ… å…ˆå†³æ¡ä»¶æ£€æŸ¥é€šè¿‡"
}

# æ„å»ºå’Œæ¨é€Dockeré•œåƒ
build_and_push() {
    echo "ğŸ”¨ æ„å»ºDockeré•œåƒ..."
    
    # ç™»å½•ECR
    aws ecr get-login-password --region $AWS_REGION | \
        docker login --username AWS --password-stdin \
        $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com
    
    # æ„å»ºé•œåƒ
    docker build -t neostock:$VERSION .
    docker tag neostock:$VERSION \
        $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:$VERSION
    
    # æ¨é€é•œåƒ
    docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:$VERSION
    
    echo "âœ… é•œåƒæ„å»ºå’Œæ¨é€å®Œæˆ"
}

# æ•°æ®åº“è¿ç§»
run_migrations() {
    echo "ğŸ—„ï¸ è¿è¡Œæ•°æ®åº“è¿ç§»..."
    
    # åˆ›å»ºè¿ç§»ä»»åŠ¡å®šä¹‰
    MIGRATION_TASK_DEF=$(aws ecs register-task-definition \
        --family neostock-migration \
        --task-role-arn $ECS_TASK_ROLE \
        --execution-role-arn $ECS_EXECUTION_ROLE \
        --network-mode awsvpc \
        --requires-compatibilities FARGATE \
        --cpu 256 \
        --memory 512 \
        --container-definitions '[{
            "name": "migration",
            "image": "'$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY:$VERSION'",
            "command": ["bun", "run", "db:migrate"],
            "environment": [
                {"name": "NODE_ENV", "value": "'$ENVIRONMENT'"},
                {"name": "DATABASE_URL", "value": "'$DATABASE_URL'"}
            ],
            "logConfiguration": {
                "logDriver": "awslogs",
                "options": {
                    "awslogs-group": "/ecs/neostock-migration",
                    "awslogs-region": "'$AWS_REGION'",
                    "awslogs-stream-prefix": "ecs"
                }
            }
        }]' \
        --query 'taskDefinition.taskDefinitionArn' \
        --output text)
    
    # è¿è¡Œè¿ç§»ä»»åŠ¡
    MIGRATION_TASK=$(aws ecs run-task \
        --cluster $ECS_CLUSTER \
        --task-definition $MIGRATION_TASK_DEF \
        --launch-type FARGATE \
        --network-configuration "awsvpcConfiguration={
            subnets=[$PRIVATE_SUBNET_IDS],
            securityGroups=[$MIGRATION_SECURITY_GROUP],
            assignPublicIp=DISABLED
        }" \
        --query 'tasks[0].taskArn' \
        --output text)
    
    # ç­‰å¾…è¿ç§»å®Œæˆ
    echo "ç­‰å¾…æ•°æ®åº“è¿ç§»å®Œæˆ..."
    aws ecs wait tasks-stopped \
        --cluster $ECS_CLUSTER \
        --tasks $MIGRATION_TASK
    
    # æ£€æŸ¥è¿ç§»ç»“æœ
    EXIT_CODE=$(aws ecs describe-tasks \
        --cluster $ECS_CLUSTER \
        --tasks $MIGRATION_TASK \
        --query 'tasks[0].containers[0].exitCode' \
        --output text)
    
    if [[ "$EXIT_CODE" != "0" ]]; then
        echo "âŒ æ•°æ®åº“è¿ç§»å¤±è´¥"
        exit 1
    fi
    
    echo "âœ… æ•°æ®åº“è¿ç§»å®Œæˆ"
}

# è“ç»¿éƒ¨ç½²
blue_green_deploy() {
    echo "ğŸ”„ æ‰§è¡Œè“ç»¿éƒ¨ç½²..."
    
    # è·å–å½“å‰æœåŠ¡çŠ¶æ€
    CURRENT_TASK_DEF=$(aws ecs describe-services \
        --cluster $ECS_CLUSTER \
        --services $ECS_SERVICE \
        --query 'services[0].taskDefinition' \
        --output text)
    
    # åˆ›å»ºæ–°çš„ä»»åŠ¡å®šä¹‰
    NEW_TASK_DEF=$(aws ecs register-task-definition \
        --family neostock-app \
        --task-role-arn $ECS_TASK_ROLE \
        --execution-role-arn $ECS_EXECUTION_ROLE \
        --network-mode awsvpc \
        --requires-compatibilities FARGATE \
        --cpu 1024 \
        --memory 2048 \
        --container-definitions file://task-definition.json \
        --query 'taskDefinition.taskDefinitionArn' \
        --output text)
    
    # æ›´æ–°æœåŠ¡
    aws ecs update-service \
        --cluster $ECS_CLUSTER \
        --service $ECS_SERVICE \
        --task-definition $NEW_TASK_DEF
    
    # ç­‰å¾…éƒ¨ç½²å®Œæˆ
    echo "ç­‰å¾…æ–°ç‰ˆæœ¬éƒ¨ç½²å®Œæˆ..."
    aws ecs wait services-stable \
        --cluster $ECS_CLUSTER \
        --services $ECS_SERVICE
    
    echo "âœ… è“ç»¿éƒ¨ç½²å®Œæˆ"
}

# å¥åº·æ£€æŸ¥
health_check() {
    echo "ğŸ¥ æ‰§è¡Œå¥åº·æ£€æŸ¥..."
    
    local max_attempts=30
    local attempt=1
    
    while [[ $attempt -le $max_attempts ]]; do
        if curl -f -s https://api.neostock.com/health > /dev/null; then
            echo "âœ… å¥åº·æ£€æŸ¥é€šè¿‡"
            return 0
        fi
        
        echo "â³ å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œé‡è¯• $attempt/$max_attempts"
        sleep 10
        ((attempt++))
    done
    
    echo "âŒ å¥åº·æ£€æŸ¥å¤±è´¥"
    return 1
}

# å›æ»šå‡½æ•°
rollback() {
    echo "ğŸ”™ æ‰§è¡Œå›æ»š..."
    
    if [[ -n "${CURRENT_TASK_DEF:-}" ]]; then
        aws ecs update-service \
            --cluster $ECS_CLUSTER \
            --service $ECS_SERVICE \
            --task-definition $CURRENT_TASK_DEF
        
        aws ecs wait services-stable \
            --cluster $ECS_CLUSTER \
            --services $ECS_SERVICE
        
        echo "âœ… å›æ»šå®Œæˆ"
    else
        echo "âŒ æ— æ³•å›æ»šï¼šæœªæ‰¾åˆ°å‰ä¸€ä¸ªä»»åŠ¡å®šä¹‰"
        exit 1
    fi
}

# ä¸»éƒ¨ç½²æµç¨‹
main() {
    trap 'echo "âŒ éƒ¨ç½²å¤±è´¥"; rollback; exit 1' ERR
    
    check_prerequisites
    build_and_push
    run_migrations
    
    if [[ "$BLUE_GREEN" == "true" ]]; then
        blue_green_deploy
    else
        # æ»šåŠ¨æ›´æ–°
        aws ecs update-service \
            --cluster $ECS_CLUSTER \
            --service $ECS_SERVICE \
            --force-new-deployment
    fi
    
    if ! health_check; then
        rollback
        exit 1
    fi
    
    echo "ğŸ‰ éƒ¨ç½²æˆåŠŸå®Œæˆ!"
}

# æ‰§è¡Œä¸»æµç¨‹
main "$@"
```

#### å¥åº·æ£€æŸ¥è„šæœ¬
```bash
#!/bin/bash
# scripts/health-check.sh

set -euo pipefail

ENDPOINT=${1:-"https://api.neostock.com"}
TIMEOUT=${2:-30}

echo "ğŸ¥ æ‰§è¡Œå…¨é¢å¥åº·æ£€æŸ¥..."

# APIå¥åº·æ£€æŸ¥
check_api_health() {
    echo "ğŸ“¡ æ£€æŸ¥APIå¥åº·çŠ¶æ€..."
    
    local response=$(curl -s -w "%{http_code}" -o /tmp/health_response "$ENDPOINT/health")
    
    if [[ "$response" == "200" ]]; then
        echo "âœ… APIå¥åº·æ£€æŸ¥é€šè¿‡"
        return 0
    else
        echo "âŒ APIå¥åº·æ£€æŸ¥å¤±è´¥: HTTP $response"
        cat /tmp/health_response
        return 1
    fi
}

# æ•°æ®åº“è¿æ¥æ£€æŸ¥
check_database() {
    echo "ğŸ—„ï¸ æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
    
    local response=$(curl -s -w "%{http_code}" -o /tmp/db_response "$ENDPOINT/health/database")
    
    if [[ "$response" == "200" ]]; then
        echo "âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸"
        return 0
    else
        echo "âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: HTTP $response"
        return 1
    fi
}

# å¤–éƒ¨æœåŠ¡æ£€æŸ¥
check_external_services() {
    echo "ğŸ”— æ£€æŸ¥å¤–éƒ¨æœåŠ¡è¿æ¥..."
    
    # Tushare APIæ£€æŸ¥
    local response=$(curl -s -w "%{http_code}" -o /tmp/tushare_response "$ENDPOINT/health/tushare")
    
    if [[ "$response" == "200" ]]; then
        echo "âœ… Tushare APIè¿æ¥æ­£å¸¸"
    else
        echo "âš ï¸ Tushare APIè¿æ¥å¼‚å¸¸: HTTP $response"
    fi
    
    return 0
}

# æ€§èƒ½æ£€æŸ¥
check_performance() {
    echo "âš¡ æ£€æŸ¥APIæ€§èƒ½..."
    
    local start_time=$(date +%s%N)
    curl -s "$ENDPOINT/api/stocks/list" > /dev/null
    local end_time=$(date +%s%N)
    
    local duration=$(( (end_time - start_time) / 1000000 ))
    
    if [[ $duration -lt 2000 ]]; then
        echo "âœ… APIå“åº”æ—¶é—´æ­£å¸¸: ${duration}ms"
        return 0
    else
        echo "âš ï¸ APIå“åº”æ—¶é—´è¿‡æ…¢: ${duration}ms"
        return 1
    fi
}

# ä¸»æ£€æŸ¥æµç¨‹
main() {
    local failed_checks=0
    
    check_api_health || ((failed_checks++))
    check_database || ((failed_checks++))
    check_external_services || ((failed_checks++))
    check_performance || ((failed_checks++))
    
    if [[ $failed_checks -eq 0 ]]; then
        echo "ğŸ‰ æ‰€æœ‰å¥åº·æ£€æŸ¥é€šè¿‡!"
        exit 0
    else
        echo "âŒ $failed_checks é¡¹æ£€æŸ¥å¤±è´¥"
        exit 1
    fi
}

main "$@"
```

### ç›‘æ§é…ç½®

#### DataDogç›‘æ§é…ç½®
```yaml
# monitoring/datadog.yml
api_key: ${DATADOG_API_KEY}
site: datadoghq.com
dd_url: https://app.datadoghq.com

# æ—¥å¿—é…ç½®
logs_enabled: true
logs_config:
  container_collect_all: true
  
# APMé…ç½®
apm_config:
  enabled: true
  env: production
  
# è¿›ç¨‹ç›‘æ§
process_config:
  enabled: true
  
# ç½‘ç»œç›‘æ§
network_config:
  enabled: true

# è‡ªå®šä¹‰æ£€æŸ¥
init_config:

instances:
  - name: neostock_api
    url: https://api.neostock.com/health
    timeout: 30
    method: GET
    expected_code: 200
    
  - name: neostock_database
    url: https://api.neostock.com/health/database
    timeout: 30
    method: GET
    expected_code: 200
```

#### å‘Šè­¦è§„åˆ™é…ç½®
```yaml
# monitoring/alerts.yml
alerts:
  - name: "é«˜é”™è¯¯ç‡å‘Šè­¦"
    type: "metric alert"
    query: "avg(last_5m):avg:neostock.api.error_rate{env:production} > 0.05"
    message: |
      APIé”™è¯¯ç‡è¶…è¿‡5%
      
      è¯·æ£€æŸ¥:
      1. åº”ç”¨æ—¥å¿—
      2. æ•°æ®åº“è¿æ¥
      3. å¤–éƒ¨æœåŠ¡çŠ¶æ€
      
      @slack-alerts @pagerduty
    tags:
      - "service:neostock"
      - "env:production"
      - "severity:critical"
    
  - name: "APIå“åº”æ—¶é—´å‘Šè­¦"
    type: "metric alert"
    query: "avg(last_5m):avg:neostock.api.response_time{env:production} > 5000"
    message: |
      APIå¹³å‡å“åº”æ—¶é—´è¶…è¿‡5ç§’
      
      @slack-alerts
    tags:
      - "service:neostock"
      - "env:production"
      - "severity:warning"
    
  - name: "æ•°æ®æ‹‰å–å¤±è´¥å‘Šè­¦"
    type: "metric alert"
    query: "sum(last_15m):sum:neostock.data.fetch_failures{env:production} > 3"
    message: |
      æ•°æ®æ‹‰å–è¿ç»­å¤±è´¥è¶…è¿‡3æ¬¡
      
      è¯·æ£€æŸ¥:
      1. Tushare APIçŠ¶æ€
      2. ç½‘ç»œè¿æ¥
      3. APIé™é¢
      
      @slack-alerts @oncall
    tags:
      - "service:neostock"
      - "env:production"
      - "severity:critical"
      
  - name: "ç£ç›˜ç©ºé—´å‘Šè­¦"
    type: "metric alert"
    query: "avg(last_5m):avg:system.disk.in_use{env:production,device:/dev/xvda1} > 0.85"
    message: |
      ç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡85%
      
      @slack-alerts
    tags:
      - "service:neostock"
      - "env:production"
      - "severity:warning"
```

### ç¾éš¾æ¢å¤

#### è‡ªåŠ¨å¤‡ä»½ç­–ç•¥
```bash
#!/bin/bash
# scripts/backup.sh

set -euo pipefail

BACKUP_TYPE=${1:-"incremental"}
S3_BUCKET="neostock-backups"
RETENTION_DAYS=30

echo "ğŸ“¦ å¼€å§‹æ‰§è¡Œ $BACKUP_TYPE å¤‡ä»½..."

# æ•°æ®åº“å¤‡ä»½
backup_database() {
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_file="neostock_${BACKUP_TYPE}_${timestamp}.db"
    
    if [[ "$BACKUP_TYPE" == "full" ]]; then
        # å…¨é‡å¤‡ä»½
        sqlite3 /var/lib/neostock/production.db ".backup /tmp/$backup_file"
    else
        # å¢é‡å¤‡ä»½ (é€šè¿‡WALæ–‡ä»¶)
        cp /var/lib/neostock/production.db-wal "/tmp/$backup_file"
    fi
    
    # å‹ç¼©å¤‡ä»½æ–‡ä»¶
    gzip "/tmp/$backup_file"
    
    # ä¸Šä¼ åˆ°S3
    aws s3 cp "/tmp/${backup_file}.gz" \
        "s3://$S3_BUCKET/database/$BACKUP_TYPE/" \
        --storage-class STANDARD_IA
    
    # æ¸…ç†æœ¬åœ°æ–‡ä»¶
    rm "/tmp/${backup_file}.gz"
    
    echo "âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: ${backup_file}.gz"
}

# é…ç½®å¤‡ä»½
backup_config() {
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local config_file="config_${timestamp}.tar.gz"
    
    # æ‰“åŒ…é…ç½®æ–‡ä»¶
    tar -czf "/tmp/$config_file" \
        /etc/neostock/ \
        /var/lib/neostock/*.env \
        /opt/neostock/config/
    
    # ä¸Šä¼ åˆ°S3
    aws s3 cp "/tmp/$config_file" \
        "s3://$S3_BUCKET/config/" \
        --storage-class STANDARD_IA
    
    # æ¸…ç†æœ¬åœ°æ–‡ä»¶
    rm "/tmp/$config_file"
    
    echo "âœ… é…ç½®å¤‡ä»½å®Œæˆ: $config_file"
}

# æ¸…ç†æ—§å¤‡ä»½
cleanup_old_backups() {
    echo "ğŸ§¹ æ¸…ç†è¶…è¿‡ $RETENTION_DAYS å¤©çš„æ—§å¤‡ä»½..."
    
    # åˆ é™¤æ—§çš„æ•°æ®åº“å¤‡ä»½
    aws s3 ls "s3://$S3_BUCKET/database/" --recursive | \
        awk '{print $4}' | \
        while read file; do
            local file_date=$(echo "$file" | grep -oE '[0-9]{8}' | head -1)
            if [[ -n "$file_date" ]]; then
                local days_old=$(( ($(date +%s) - $(date -d "$file_date" +%s)) / 86400 ))
                if [[ $days_old -gt $RETENTION_DAYS ]]; then
                    aws s3 rm "s3://$S3_BUCKET/$file"
                    echo "åˆ é™¤æ—§å¤‡ä»½: $file"
                fi
            fi
        done
    
    echo "âœ… å¤‡ä»½æ¸…ç†å®Œæˆ"
}

# ä¸»å¤‡ä»½æµç¨‹
main() {
    backup_database
    backup_config
    cleanup_old_backups
    
    echo "ğŸ‰ å¤‡ä»½ä»»åŠ¡å®Œæˆ!"
}

main "$@"
```

#### ç¾éš¾æ¢å¤ç¨‹åº
```bash
#!/bin/bash
# scripts/disaster-recovery.sh

set -euo pipefail

RECOVERY_TYPE=${1:-"latest"}
S3_BUCKET="neostock-backups"

echo "ğŸš¨ å¼€å§‹ç¾éš¾æ¢å¤ç¨‹åº..."
echo "æ¢å¤ç±»å‹: $RECOVERY_TYPE"

# åœæ­¢åº”ç”¨æœåŠ¡
stop_services() {
    echo "â¹ï¸ åœæ­¢åº”ç”¨æœåŠ¡..."
    
    systemctl stop neostock-app
    systemctl stop neostock-worker
    
    echo "âœ… æœåŠ¡å·²åœæ­¢"
}

# æ¢å¤æ•°æ®åº“
restore_database() {
    echo "ğŸ—„ï¸ æ¢å¤æ•°æ®åº“..."
    
    local backup_file
    if [[ "$RECOVERY_TYPE" == "latest" ]]; then
        # è·å–æœ€æ–°çš„å…¨é‡å¤‡ä»½
        backup_file=$(aws s3 ls "s3://$S3_BUCKET/database/full/" | \
            sort | tail -1 | awk '{print $4}')
    else
        # ä½¿ç”¨æŒ‡å®šçš„å¤‡ä»½æ–‡ä»¶
        backup_file="$RECOVERY_TYPE"
    fi
    
    if [[ -z "$backup_file" ]]; then
        echo "âŒ æœªæ‰¾åˆ°å¤‡ä»½æ–‡ä»¶"
        exit 1
    fi
    
    echo "ä½¿ç”¨å¤‡ä»½æ–‡ä»¶: $backup_file"
    
    # å¤‡ä»½å½“å‰æ•°æ®åº“
    if [[ -f /var/lib/neostock/production.db ]]; then
        mv /var/lib/neostock/production.db \
           /var/lib/neostock/production.db.recovery_backup
    fi
    
    # ä¸‹è½½å¹¶æ¢å¤å¤‡ä»½
    aws s3 cp "s3://$S3_BUCKET/database/full/$backup_file" /tmp/
    gunzip "/tmp/$backup_file"
    
    local db_file=$(basename "$backup_file" .gz)
    mv "/tmp/$db_file" /var/lib/neostock/production.db
    
    # è®¾ç½®æ­£ç¡®çš„æƒé™
    chown neostock:neostock /var/lib/neostock/production.db
    chmod 644 /var/lib/neostock/production.db
    
    echo "âœ… æ•°æ®åº“æ¢å¤å®Œæˆ"
}

# éªŒè¯æ•°æ®å®Œæ•´æ€§
verify_data_integrity() {
    echo "ğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§..."
    
    # SQLiteå®Œæ•´æ€§æ£€æŸ¥
    sqlite3 /var/lib/neostock/production.db "PRAGMA integrity_check;" | \
        grep -q "ok" || {
            echo "âŒ æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥"
            exit 1
        }
    
    # æ£€æŸ¥å…³é”®è¡¨
    local table_count=$(sqlite3 /var/lib/neostock/production.db \
        "SELECT COUNT(*) FROM sqlite_master WHERE type='table';")
    
    if [[ $table_count -lt 5 ]]; then
        echo "âŒ æ•°æ®åº“è¡¨æ•°é‡å¼‚å¸¸: $table_count"
        exit 1
    fi
    
    echo "âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡"
}

# å¯åŠ¨æœåŠ¡å¹¶éªŒè¯
start_and_verify() {
    echo "ğŸš€ å¯åŠ¨æœåŠ¡..."
    
    systemctl start neostock-app
    systemctl start neostock-worker
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    sleep 30
    
    # å¥åº·æ£€æŸ¥
    if curl -f -s http://localhost:3000/health > /dev/null; then
        echo "âœ… æœåŠ¡å¯åŠ¨æˆåŠŸ"
    else
        echo "âŒ æœåŠ¡å¯åŠ¨å¤±è´¥"
        exit 1
    fi
}

# å‘é€é€šçŸ¥
send_notification() {
    local status=$1
    local message="ç¾éš¾æ¢å¤ $status\n\n"
    message+="æ¢å¤ç±»å‹: $RECOVERY_TYPE\n"
    message+="æ—¶é—´: $(date)\n"
    message+="æœåŠ¡å™¨: $(hostname)"
    
    # Slacké€šçŸ¥
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"$message\"}" \
        "$SLACK_WEBHOOK_URL"
    
    # é‚®ä»¶é€šçŸ¥
    echo "$message" | mail -s "neostock ç¾éš¾æ¢å¤ $status" \
        ops@neostock.com
}

# ä¸»æ¢å¤æµç¨‹
main() {
    trap 'send_notification "å¤±è´¥"; exit 1' ERR
    
    stop_services
    restore_database
    verify_data_integrity
    start_and_verify
    
    send_notification "æˆåŠŸ"
    echo "ğŸ‰ ç¾éš¾æ¢å¤å®Œæˆ!"
}

main "$@"
```

## ç›‘æ§å’Œç»´æŠ¤

### æ€§èƒ½ç›‘æ§

#### å…³é”®æŒ‡æ ‡
- **APIå“åº”æ—¶é—´**: å¹³å‡ < 1s, 95th percentile < 3s
- **é”™è¯¯ç‡**: < 1%
- **æ•°æ®åº“æŸ¥è¯¢æ—¶é—´**: å¹³å‡ < 100ms
- **å†…å­˜ä½¿ç”¨ç‡**: < 80%
- **CPUä½¿ç”¨ç‡**: < 70%
- **ç£ç›˜ä½¿ç”¨ç‡**: < 85%

#### ä¸šåŠ¡æŒ‡æ ‡
- **ç”¨æˆ·æ´»è·ƒåº¦**: DAU, MAU
- **åŠŸèƒ½ä½¿ç”¨ç‡**: æœç´¢ã€å›æµ‹ã€åˆ†æåŠŸèƒ½ä½¿ç”¨ç»Ÿè®¡
- **æ•°æ®è´¨é‡**: æ•°æ®æ‹‰å–æˆåŠŸç‡ã€æ•°æ®å®Œæ•´æ€§
- **ç”¨æˆ·æ»¡æ„åº¦**: APIå“åº”æ—¶é—´åˆ†å¸ƒã€é”™è¯¯å½±å“ç”¨æˆ·æ•°

### æ—¥å¸¸ç»´æŠ¤

#### æ¯æ—¥æ£€æŸ¥æ¸…å•
```bash
#!/bin/bash
# scripts/daily-check.sh

echo "ğŸ“… æ‰§è¡Œæ¯æ—¥ç³»ç»Ÿæ£€æŸ¥..."

# æ£€æŸ¥ç³»ç»Ÿèµ„æº
echo "ğŸ’¾ ç³»ç»Ÿèµ„æºçŠ¶æ€:"
df -h | grep -v tmpfs
free -h
top -bn1 | head -5

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ”§ æœåŠ¡çŠ¶æ€:"
systemctl status neostock-app --no-pager -l
systemctl status neostock-worker --no-pager -l

# æ£€æŸ¥æ—¥å¿—é”™è¯¯
echo "ğŸ“‹ æœ€è¿‘24å°æ—¶é”™è¯¯æ—¥å¿—:"
journalctl -u neostock-app --since "24 hours ago" --no-pager | \
    grep -i error | tail -10

# æ£€æŸ¥æ•°æ®æ‹‰å–çŠ¶æ€
echo "ğŸ“Š æ•°æ®æ‹‰å–çŠ¶æ€:"
tail -20 /var/log/neostock/data-fetch.log

# æ£€æŸ¥å¤‡ä»½çŠ¶æ€
echo "ğŸ“¦ å¤‡ä»½çŠ¶æ€:"
aws s3 ls s3://neostock-backups/database/incremental/ | tail -5

echo "âœ… æ¯æ—¥æ£€æŸ¥å®Œæˆ"
```

#### å‘¨ç»´æŠ¤ä»»åŠ¡
```bash
#!/bin/bash
# scripts/weekly-maintenance.sh

echo "ğŸ“… æ‰§è¡Œå‘¨ç»´æŠ¤ä»»åŠ¡..."

# æ•°æ®åº“ä¼˜åŒ–
echo "ğŸ—„ï¸ æ•°æ®åº“ä¼˜åŒ–..."
sqlite3 /var/lib/neostock/production.db "VACUUM;"
sqlite3 /var/lib/neostock/production.db "ANALYZE;"

# æ—¥å¿—è½®è½¬
echo "ğŸ“‹ æ—¥å¿—è½®è½¬..."
logrotate /etc/logrotate.d/neostock

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
echo "ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
find /tmp -name "neostock*" -mtime +7 -delete
find /var/log/neostock -name "*.log.*" -mtime +30 -delete

# æ›´æ–°ç³»ç»ŸåŒ…
echo "ğŸ“¦ æ›´æ–°ç³»ç»ŸåŒ…..."
apt update && apt upgrade -y

# å®‰å…¨æ‰«æ
echo "ğŸ”’ å®‰å…¨æ‰«æ..."
rkhunter --check --skip-keypress
lynis audit system --quiet

echo "âœ… å‘¨ç»´æŠ¤ä»»åŠ¡å®Œæˆ"
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è¯Šæ–­

#### åº”ç”¨æ— æ³•å¯åŠ¨
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
systemctl status neostock-app

# æ£€æŸ¥æ—¥å¿—
journalctl -u neostock-app --no-pager -l

# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tulpn | grep :3000

# æ£€æŸ¥é…ç½®æ–‡ä»¶
cat /etc/neostock/production.env
```

#### æ•°æ®åº“è¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æƒé™
ls -la /var/lib/neostock/production.db

# æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
sqlite3 /var/lib/neostock/production.db "PRAGMA integrity_check;"

# æ£€æŸ¥æ•°æ®åº“å¤§å°
du -sh /var/lib/neostock/

# æ£€æŸ¥WALæ–‡ä»¶
ls -la /var/lib/neostock/*.db-*
```

#### æ€§èƒ½é—®é¢˜
```bash
# æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½
uptime
iostat 1 5

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
ps aux --sort=-%mem | head -10

# æ£€æŸ¥æ•°æ®åº“æŸ¥è¯¢
sqlite3 /var/lib/neostock/production.db ".timer on" "SELECT COUNT(*) FROM stocks;"

# æ£€æŸ¥ç½‘ç»œè¿æ¥
ss -tuln
netstat -i
```

### ç´§æ€¥å“åº”ç¨‹åº

#### æœåŠ¡ä¸­æ–­å“åº”
1. **ç«‹å³å“åº”** (5åˆ†é’Ÿå†…)
   - ç¡®è®¤é—®é¢˜èŒƒå›´
   - é€šçŸ¥ç›¸å…³äººå‘˜
   - å¼€å§‹æ•…éšœæ’æŸ¥

2. **é—®é¢˜è¯Šæ–­** (15åˆ†é’Ÿå†…)
   - æ£€æŸ¥ç›‘æ§æ•°æ®
   - åˆ†æé”™è¯¯æ—¥å¿—
   - ç¡®å®šæ ¹æœ¬åŸå› 

3. **ä¸´æ—¶ä¿®å¤** (30åˆ†é’Ÿå†…)
   - å®æ–½ä¸´æ—¶è§£å†³æ–¹æ¡ˆ
   - æ¢å¤æ ¸å¿ƒåŠŸèƒ½
   - ç›‘æ§ä¿®å¤æ•ˆæœ

4. **æ°¸ä¹…ä¿®å¤** (2å°æ—¶å†…)
   - å®æ–½æ°¸ä¹…è§£å†³æ–¹æ¡ˆ
   - å®Œæ•´æµ‹è¯•éªŒè¯
   - æ›´æ–°æ–‡æ¡£å’Œç¨‹åº

5. **äº‹ååˆ†æ** (24å°æ—¶å†…)
   - æ’°å†™äº‹æ•…æŠ¥å‘Š
   - åˆ†ææ ¹æœ¬åŸå› 
   - åˆ¶å®šé¢„é˜²æªæ–½

è¿™ä¸ªéƒ¨ç½²è¿ç»´æ‰‹å†Œæä¾›äº† neostock é¡¹ç›®å®Œæ•´çš„ç”Ÿäº§ç¯å¢ƒç®¡ç†æŒ‡å—ï¼Œç¡®ä¿ç³»ç»Ÿçš„é«˜å¯ç”¨æ€§ã€å¯ç»´æŠ¤æ€§å’Œå®‰å…¨æ€§ã€‚